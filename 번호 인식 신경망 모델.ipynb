{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LooAgXUbdBe_"
      },
      "source": [
        "# 번호판 인식 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J54FphnkdFHh"
      },
      "source": [
        "OpenCV와 tensorflow를 이용한 번호판 인식 프로그램 입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BgJPmW0dLOp"
      },
      "source": [
        "## 모듈 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eM41aRljYS7H"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, Input, Model\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZXsR6HYdNhk"
      },
      "source": [
        "## MNIST 데이터 불러오기 및 정규화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ6rQKNKa4V6",
        "outputId": "bdf1c9c8-6b88-4e1c-c207-2e43dc67d744"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# 픽셀 값을 0~1 사이로 정규화합니다.\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei3y_UlwdVHT"
      },
      "source": [
        "## CNN 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wY0nS99YfUI",
        "outputId": "c71948d2-962a-419c-bdd1-d3e172e9e434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                36928     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# CNN 모델을 생성한다.\n",
        "\n",
        "# Convoultion 한 후 Output size 는 다음과 같이 계산된다.\n",
        "# (W - F + 2P) / S + 1\n",
        "# W : 원래 이미지 크기\n",
        "# F : 커널의 크기\n",
        "# P : 패딩의 크기 (패딩은 이미지 바깥에 임의의 값 영역을 추가로 주는 것을 의미. 보통 0으로 주는 Zero-Padding 방식을 사용)\n",
        "# S : Stride의 크기 (커널의 이동 거리. 기본값은 1)\n",
        "\n",
        "# MaxPooling 한 후 Output size 는 다음과 같이 계산된다.\n",
        "# (W - M) / S + 1\n",
        "# W : 원래 이미지의 크기\n",
        "# M : Pooling 커널의 크기\n",
        "# S : Stride의 크기 (Pooling 커널의 이동 거리. Convoultion과 다르게 Pooling의 기본 Stride값은 2 이다.)\n",
        "\n",
        "i = Input(shape=(28, 28, 1)) # 첫번째 층. 입력레이어. 28*28*1의 이미지\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(i) # 3 * 3 커널 32개를 지니는 Convolution 레이어\n",
        "\n",
        "                                       # 출력 : (28 - 3 + 0) / 1 + 1 = 26 이고 32개의 커널이 존재하므로 최종적으로 26 * 26 * 32 의 output size를 가진다.\n",
        "\n",
        "x = layers.MaxPooling2D((2, 2))(x) # 각 26 * 26 에서 2 * 2의 크기를 지니는 커널을 이동시켜가며 가장 큰 값을 뽑아내는 Max Pooling 레이어\n",
        "\n",
        "                                       # 출력 : (26 - 2) / 2 + 1 = 13 이고 들어온 input이 32개 이므로 최종적으로 13 * 13 * 32 의 output size를 가진다.\n",
        "\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x) # 64개의 3 * 3 커널을 사용하는 Convolution 레이어\n",
        "\n",
        "# 출력 : (13 - 3 + 0) / 1 + 1 =  11, 결과 : 11 * 11 * 64\n",
        "\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# 출력 : (11 - 2) / 2 + 1 = 5, 결과 : 5 * 5 * 64\n",
        "\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "\n",
        "# 출력 : (5 - 3 + 0) / 1 + 1 = 3, 결과 : 3 * 3 * 64\n",
        "\n",
        "x = layers.Flatten()(x) # 완전연결신경망으로 데이터를 전달하기위해서 이미지를 1차원 벡터로 펼쳐주는 층. 9 * 9 * 64 = 5184의 1차원 벡터를 생성함.\n",
        "\n",
        "x2 = layers.Dense(64, activation='relu')(x) # 64개의 노드를 지니는 일반 층\n",
        "y = layers.Dense(10, activation='softmax')(x2) # 10개의 노드를 지니는 일반층(class 분류 결과를 보여주기위해 softmax 활성화 함수 사용)\n",
        "model = Model(inputs=i,outputs=y)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-D-qQpZdYSo"
      },
      "source": [
        "## 모델 컴파일 및 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yTb646TZiD0",
        "outputId": "c0e79567-1428-4ae5-eb56-6b77ceeae2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1554 - accuracy: 0.9512\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0461 - accuracy: 0.9858\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0337 - accuracy: 0.9895\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0259 - accuracy: 0.9921\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0225 - accuracy: 0.9927\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x12804538310>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "전이학습 전에 손글씨 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "roi = cv.imread(\"./handwriting/8.png\")\n",
        "\n",
        "roi_gray = cv.cvtColor(roi,cv.COLOR_BGR2GRAY)\n",
        "thr = cv.adaptiveThreshold(roi_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2) # 이진화 시킴. 방식은 apdative threshold\n",
        "thr = cv.resize(thr, dsize=(28, 28), interpolation=cv.INTER_AREA)\n",
        "thr = thr.reshape((28,28,1))\n",
        "thr = thr / 255.0\n",
        "\n",
        "np.argmax(model.predict(np.expand_dims(thr,0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4MZQjRTddSU"
      },
      "source": [
        "## 실제 번호판 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dML76EfnYd4Z"
      },
      "outputs": [],
      "source": [
        "image_list = os.listdir('./imgs') # imgs라는 폴더 안의 모든 파일명을 가져옵니다.\n",
        "#print(image_list)\n",
        "\n",
        "roi_list = [] # 실제 프로그램 내에서 사용될 리스트.\n",
        "labels = [] # 실제 프로그램 내에서 사용될 target값.\n",
        "\n",
        "for img in image_list:\n",
        "  roi = cv.imread('./imgs/'+img) # imgs 폴더에 있는 이미지 하나씩 불러옴\n",
        "  roi_gray = cv.cvtColor(roi,cv.COLOR_BGR2GRAY) # 흑백으로 변환\n",
        "  thr = cv.adaptiveThreshold(roi_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2) # 이진화 시킴. 방식은 apdative threshold\n",
        "  thr = cv.resize(thr, dsize=(28, 28), interpolation=cv.INTER_AREA) # 28 * 28 으로 이미지 크기 변환\n",
        "  thr = thr / 255.0 # 0~1 사이의 값으로 정규화\n",
        "  thr = thr.reshape((28,28,1)) # 딥러닝 모듈에 집어넣기 위해서 2차원 흑백이미지를 3차원으로 변환\n",
        "\n",
        "  roi_list.append(thr) # 리스트에 추가\n",
        "  labels.append(int(img[0])) # 파일명의 맨 앞글자(숫자)로 라벨을 지정하고 리스트에 추가\n",
        "\n",
        "train_images2 = np.array(roi_list) # 학습될 이미지 numpy array로 변환\n",
        "train_labels2 = np.array(labels) # 학습될 라벨 numpy array로 변환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz6yvisKdkSv"
      },
      "source": [
        "## 전이 학습을 위한 Weight Freezing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gr4c9YgmbDwN"
      },
      "outputs": [],
      "source": [
        "x.trainable = False # Convolution Layer들은 학습시키지 않는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4kPzZn3ds_Y"
      },
      "source": [
        "## MNIST데이터로 학습된 모델에 번호판 데이터로 전이학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ_EItita795",
        "outputId": "1bfb5c2c-54e2-4cff-bd56-b934ff36d5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 1s 11ms/step - loss: 0.3625 - accuracy: 0.8959\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0572 - accuracy: 0.9953\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9968\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.9968\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9984\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x21f89ce63b0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_images2, train_labels2, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCQigJUHdzYo"
      },
      "source": [
        "## 임의의 데이터로 성능테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPnzUzBFh1l7",
        "outputId": "7eb7bdf2-8bf0-41e2-fe4f-2c2d0faed88e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "roi = cv.imread(\"./handwriting/0.png\")\n",
        "\n",
        "roi_gray = cv.cvtColor(roi,cv.COLOR_BGR2GRAY)\n",
        "thr = cv.adaptiveThreshold(roi_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2) # 이진화 시킴. 방식은 apdative threshold\n",
        "thr = cv.resize(thr, dsize=(28, 28), interpolation=cv.INTER_AREA)\n",
        "thr = thr.reshape((28,28,1))\n",
        "thr = thr / 255.0\n",
        "\n",
        "np.argmax(model.predict(np.expand_dims(thr,0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8DaODGyd27e"
      },
      "source": [
        "## 학습한 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzLpCIbdFI-x"
      },
      "outputs": [],
      "source": [
        "model.save('my_cnn_model_new.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "자동차번호판개선.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "8bf0d51478355d2251941b3b98616086516a0eddd7c72ee47a3371765770709a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
